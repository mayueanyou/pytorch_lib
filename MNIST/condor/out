Quadro RTX 6000
module name:  FNN_1
total parameters: 7,850
best validate accuracy: 92.36%
best test accuracy: 92.39%
best test loss: 0.267649
total parameters: 7,850

batch size: 64
data in total:  train[48000] test[10000] validate[12000]
data per batch: train[750] test[156] validate[187]

Epoch 1
-------------------------------
[    0/48000]loss: 2.360513
[ 6400/48000]loss: 1.019700
[12800/48000]loss: 0.567658
[19200/48000]loss: 0.486702
[25600/48000]loss: 0.451238
[32000/48000]loss: 0.274997
[38400/48000]loss: 0.754326
[44800/48000]loss: 0.377108
net:
Validate: 
 Accuracy: 89.99%, Avg loss: 0.364532 

Test: 
 Accuracy: 90.42%, Avg loss: 0.355900 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 2
-------------------------------
[    0/48000]loss: 0.329222
[ 6400/48000]loss: 0.421571
[12800/48000]loss: 0.234530
[19200/48000]loss: 0.326811
[25600/48000]loss: 0.321042
[32000/48000]loss: 0.168123
[38400/48000]loss: 0.694815
[44800/48000]loss: 0.309600
net:
Validate: 
 Accuracy: 91.20%, Avg loss: 0.313518 

Test: 
 Accuracy: 91.50%, Avg loss: 0.306656 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 3
-------------------------------
[    0/48000]loss: 0.298230
[ 6400/48000]loss: 0.343729
[12800/48000]loss: 0.184982
[19200/48000]loss: 0.288554
[25600/48000]loss: 0.280300
[32000/48000]loss: 0.140609
[38400/48000]loss: 0.669715
[44800/48000]loss: 0.276030
net:
Validate: 
 Accuracy: 91.62%, Avg loss: 0.294814 

Test: 
 Accuracy: 91.83%, Avg loss: 0.289190 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 4
-------------------------------
[    0/48000]loss: 0.293651
[ 6400/48000]loss: 0.308901
[12800/48000]loss: 0.166929
[19200/48000]loss: 0.267379
[25600/48000]loss: 0.257557
[32000/48000]loss: 0.128944
[38400/48000]loss: 0.655639
[44800/48000]loss: 0.254147
net:
Validate: 
 Accuracy: 91.97%, Avg loss: 0.285209 

Test: 
 Accuracy: 92.03%, Avg loss: 0.280499 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 5
-------------------------------
[    0/48000]loss: 0.293637
[ 6400/48000]loss: 0.288329
[12800/48000]loss: 0.158537
[19200/48000]loss: 0.253163
[25600/48000]loss: 0.242727
[32000/48000]loss: 0.122545
[38400/48000]loss: 0.646932
[44800/48000]loss: 0.238440
net:
Validate: 
 Accuracy: 92.09%, Avg loss: 0.279481 

Test: 
 Accuracy: 92.16%, Avg loss: 0.275461 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 6
-------------------------------
[    0/48000]loss: 0.294335
[ 6400/48000]loss: 0.274180
[12800/48000]loss: 0.153980
[19200/48000]loss: 0.242700
[25600/48000]loss: 0.232340
[32000/48000]loss: 0.118381
[38400/48000]loss: 0.641072
[44800/48000]loss: 0.226543
net:
Validate: 
 Accuracy: 92.17%, Avg loss: 0.275756 

Test: 
 Accuracy: 92.32%, Avg loss: 0.272275 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 7
-------------------------------
[    0/48000]loss: 0.294878
[ 6400/48000]loss: 0.263491
[12800/48000]loss: 0.151192
[19200/48000]loss: 0.234531
[25600/48000]loss: 0.224749
[32000/48000]loss: 0.115324
[38400/48000]loss: 0.636824
[44800/48000]loss: 0.217184
net:
Validate: 
 Accuracy: 92.21%, Avg loss: 0.273196 

Test: 
 Accuracy: 92.36%, Avg loss: 0.270147 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 8
-------------------------------
[    0/48000]loss: 0.295103
[ 6400/48000]loss: 0.254934
[12800/48000]loss: 0.149311
[19200/48000]loss: 0.227888
[25600/48000]loss: 0.219037
[32000/48000]loss: 0.112878
[38400/48000]loss: 0.633563
[44800/48000]loss: 0.209610
net:
Validate: 
 Accuracy: 92.31%, Avg loss: 0.271372 

Test: 
 Accuracy: 92.40%, Avg loss: 0.268679 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 9
-------------------------------
[    0/48000]loss: 0.295033
[ 6400/48000]loss: 0.247838
[12800/48000]loss: 0.147920
[19200/48000]loss: 0.222333
[25600/48000]loss: 0.214639
[32000/48000]loss: 0.110802
[38400/48000]loss: 0.630957
[44800/48000]loss: 0.203345
net:
Validate: 
 Accuracy: 92.36%, Avg loss: 0.270041 

Test: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

Epoch 10
-------------------------------
[    0/48000]loss: 0.294732
[ 6400/48000]loss: 0.241819
[12800/48000]loss: 0.146807
[19200/48000]loss: 0.217599
[25600/48000]loss: 0.211181
[32000/48000]loss: 0.108969
[38400/48000]loss: 0.628817
[44800/48000]loss: 0.198076
net:
Validate: 
 Accuracy: 92.34%, Avg loss: 0.269057 

Test: 
 Accuracy: 92.39%, Avg loss: 0.266926 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

batch size: 64
data in total:  train[48000] test[10000] validate[12000]
data per batch: train[750] test[156] validate[187]

net:
Validate: 
 Accuracy: 92.34%, Avg loss: 0.269057 

Test: 
 Accuracy: 92.39%, Avg loss: 0.266926 

Best: 
 Accuracy: 92.39%, Avg loss: 0.267649 

